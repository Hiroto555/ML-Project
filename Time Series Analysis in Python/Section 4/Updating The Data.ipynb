{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary package \n",
    "# Make sure to pip install it in Anaconda, if you don't have it\n",
    "import yfinance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yfinance\n",
      "  Downloading yfinance-0.2.3-py2.py3-none-any.whl (50 kB)\n",
      "Collecting multitasking>=0.0.7\n",
      "  Downloading multitasking-0.0.11-py3-none-any.whl (8.5 kB)\n",
      "Requirement already satisfied: requests>=2.26 in c:\\users\\shgol\\anaconda3\\lib\\site-packages (from yfinance) (2.27.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\shgol\\anaconda3\\lib\\site-packages (from yfinance) (1.21.5)\n",
      "Collecting pytz>=2022.5\n",
      "  Downloading pytz-2022.7-py2.py3-none-any.whl (499 kB)\n",
      "Requirement already satisfied: cryptography>=3.3.2 in c:\\users\\shgol\\anaconda3\\lib\\site-packages (from yfinance) (3.4.8)\n",
      "Collecting html5lib>=1.1\n",
      "  Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "Requirement already satisfied: pandas>=1.3.0 in c:\\users\\shgol\\anaconda3\\lib\\site-packages (from yfinance) (1.4.2)\n",
      "Collecting lxml>=4.9.1\n",
      "  Downloading lxml-4.9.2-cp39-cp39-win_amd64.whl (3.9 MB)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in c:\\users\\shgol\\anaconda3\\lib\\site-packages (from yfinance) (4.11.1)\n",
      "Collecting frozendict>=2.3.4\n",
      "  Downloading frozendict-2.3.4-cp39-cp39-win_amd64.whl (35 kB)\n",
      "Requirement already satisfied: appdirs>=1.4.4 in c:\\users\\shgol\\anaconda3\\lib\\site-packages (from yfinance) (1.4.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\shgol\\anaconda3\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.3.1)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\shgol\\anaconda3\\lib\\site-packages (from cryptography>=3.3.2->yfinance) (1.15.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\shgol\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=3.3.2->yfinance) (2.21)\n",
      "Requirement already satisfied: webencodings in c:\\users\\shgol\\anaconda3\\lib\\site-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\shgol\\anaconda3\\lib\\site-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\shgol\\anaconda3\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shgol\\anaconda3\\lib\\site-packages (from requests>=2.26->yfinance) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\shgol\\anaconda3\\lib\\site-packages (from requests>=2.26->yfinance) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\shgol\\anaconda3\\lib\\site-packages (from requests>=2.26->yfinance) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shgol\\anaconda3\\lib\\site-packages (from requests>=2.26->yfinance) (3.3)\n",
      "Installing collected packages: pytz, multitasking, lxml, html5lib, frozendict, yfinance\n",
      "  Attempting uninstall: pytz\n",
      "    Found existing installation: pytz 2021.3\n",
      "    Uninstalling pytz-2021.3:\n",
      "      Successfully uninstalled pytz-2021.3\n",
      "  Attempting uninstall: lxml\n",
      "    Found existing installation: lxml 4.8.0\n",
      "    Uninstalling lxml-4.8.0:\n",
      "      Successfully uninstalled lxml-4.8.0\n",
      "Successfully installed frozendict-2.3.4 html5lib-1.1 lxml-4.9.2 multitasking-0.0.11 pytz-2022.7 yfinance-0.2.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda-repo-cli 1.0.4 requires pathlib, which is not installed.\n"
     ]
    }
   ],
   "source": [
    "!pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignoring warning messages\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "download() got an unexpected keyword argument 'treads'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Using the .download() method to get our data\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m raw_data \u001b[38;5;241m=\u001b[39m \u001b[43myfinance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtickers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m^GSPC ^FTSE ^N225 ^GDAXI\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#The time series we are interested in - (in our case, these are the S&P, FTSE, NIKKEI and DAX)\u001b[39;49;00m\n\u001b[0;32m      4\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m1994-01-07\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#The starting date of our data set\u001b[39;49;00m\n\u001b[0;32m      5\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mend\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m2019-09-27\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#The ending date of our data set (at the time of upload, this is the current date)\u001b[39;49;00m\n\u001b[0;32m      6\u001b[0m \u001b[43m                              \u001b[49m\u001b[43minterval\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m1d\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#The distance in time between two recorded observations. Since we're using daily closing prices, we set it equal to \"1d\", which indicates 1 day. \u001b[39;49;00m\n\u001b[0;32m      7\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mgroup_by\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mticker\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#The way we want to group the scraped data. Usually we want it to be \"ticker\", so that we have all the information about a time series in 1 variable.\u001b[39;49;00m\n\u001b[0;32m      8\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mauto_adjust\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#Automatically adjuss the closing prices for each period. \u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mtreads\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: download() got an unexpected keyword argument 'treads'"
     ]
    }
   ],
   "source": [
    "# Using the .download() method to get our data\n",
    "\n",
    "raw_data = yfinance.download (tickers = \"^GSPC ^FTSE ^N225 ^GDAXI\", #The time series we are interested in - (in our case, these are the S&P, FTSE, NIKKEI and DAX)\n",
    "                              start = \"1994-01-07\", #The starting date of our data set\n",
    "                              end = \"2019-09-27\", #The ending date of our data set (at the time of upload, this is the current date)\n",
    "                              interval = \"1d\", #The distance in time between two recorded observations. Since we're using daily closing prices, we set it equal to \"1d\", which indicates 1 day. \n",
    "                              group_by = 'ticker', #The way we want to group the scraped data. Usually we want it to be \"ticker\", so that we have all the information about a time series in 1 variable.\n",
    "                              auto_adjust = True, #Automatically adjuss the closing prices for each period. \n",
    "                              treads = True) #Whether to use threads for mass downloading. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'raw_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Creating a back up copy in case we remove/alter elements of the data by mistake\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df_comp \u001b[38;5;241m=\u001b[39m \u001b[43mraw_data\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'raw_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Creating a back up copy in case we remove/alter elements of the data by mistake\n",
    "df_comp = raw_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_comp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Adding new columns to the data set\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df_comp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspx\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_comp\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m^GSPC\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mClose\n\u001b[0;32m      3\u001b[0m df_comp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdax\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_comp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m^GDAXI\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mClose\n\u001b[0;32m      4\u001b[0m df_comp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mftse\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_comp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m^FTSE\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mClose\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_comp' is not defined"
     ]
    }
   ],
   "source": [
    "# Adding new columns to the data set\n",
    "df_comp['spx'] = df_comp['^GSPC'].Close\n",
    "df_comp['dax'] = df_comp['^GDAXI'].Close\n",
    "df_comp['ftse'] = df_comp['^FTSE'].Close\n",
    "df_comp['nikkei'] = df_comp['^N225'].Close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_comp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_comp \u001b[38;5;241m=\u001b[39m \u001b[43mdf_comp\u001b[49m\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;66;03m# Removing the first elements, since we always start 1 period before the first, due to time zone differences of closing prices\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m df_comp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m^N225\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Removing the original tickers of the data set\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m df_comp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m^GSPC\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_comp' is not defined"
     ]
    }
   ],
   "source": [
    "df_comp = df_comp.iloc[1:] # Removing the first elements, since we always start 1 period before the first, due to time zone differences of closing prices\n",
    "del df_comp['^N225']  # Removing the original tickers of the data set\n",
    "del df_comp['^GSPC']\n",
    "del df_comp['^GDAXI']\n",
    "del df_comp['^FTSE']\n",
    "df_comp=df_comp.asfreq('b') # Setting the frequency of the data\n",
    "df_comp=df_comp.fillna(method='ffill') # Filling any missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_comp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[43mdf_comp\u001b[49m\u001b[38;5;241m.\u001b[39mhead()) \u001b[38;5;66;03m# Displaying the first 5 elements to make sure the data was scrapped correctly\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m (df_comp\u001b[38;5;241m.\u001b[39mtail())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_comp' is not defined"
     ]
    }
   ],
   "source": [
    "print (df_comp.head()) # Displaying the first 5 elements to make sure the data was scrapped correctly\n",
    "print (df_comp.tail()) # Making sure of the last day we're including in the series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
